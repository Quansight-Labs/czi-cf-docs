---
sidebar_position: 4
---

# Infrastructure guide

conda-forge operates at a scale where automation is not an option.
Most processes are automated so human intervention is kept to a minimum.

In this page, we discuss the different elements involved in each stage of the [conda packaging life cycle](/docs/user/life-cycle/index.md):

<!-- TODO: Discuss infrasture elements first and link to them from the user/life-cycle document -->

1. Initial submission to `staged-recipes`
2. Feedstock changes:
   - A. Repository initialization
   - B. Automated maintenance updates
   - C. PRs submitted by users
3. Package building
4. Package validation and publication
5. Post-publication:
   - A. Repodata patch
   - B. Mark a package as broken
6. Feedstock operations
   - Archive a feedstock
   - Regenerate tokens

## 1. Initial submission to staged-recipes

The `conda-forge/staged-recipes` repository uses several pieces of infrastructure.

On pull requests:

- Package building pipelines. These are slightly different than the ones running in feedstocks (they are not automatically generated by `conda-smithy`, but they do use the same underlying components).
- The linter provided by `conda-smithy recipe-lint`, run by `@conda-forge-linter`.
- Auto-labeling logic, run by Github Actions workflows.

On pushes to `main`:

- Create and initialize the new feedstocks.

Authenticated services involved:

- Github, with permissions for:
  - Repository creation
- Azure Pipelines
- Travis CI
- Other CI providers?

## 2. Feedstock changes

A feedstock can receive changes for several reasons.

Pushes to `main` or other branches:

- The automated initialization commits following the approval in `staged-recipes`. These are generated by `conda-smithy`.
- Automated maintenance commits triggered from `admin-migrations`.
- Rerender requests handled by instances of `conda-forge/webservices-dispatch-action` and triggered by the admin web service.

Automatic pull requests can be opened by...

- `@conda-forge-linter`, responding to some issues with titlesman like `@conda-forge-admin, please...`.
- `@regro-cf-autotick-bot`, handling migrations and new versions being available.

...and closed by:

- `conda-forge/automerge-action`, if labeled adequately.

On an open pull request:

- The building pipelines (more [below](#3-package-building)).
- The linter provided by `conda-smithy recipe-lint`, run by `@conda-forge-linter`.
- The `@conda-forge-admin, please...` command comments, answered by `@conda-forge-linter`.

On issues:

- `@conda-forge-admin, please...` command issues, handled by `@conda-forge-linter`.

:::tip
See [Addendum below](#operations-on-feedstocks) for more information about operations on feedstocks.
These include operations on feedstock metadata and/or contents.
:::

## 3. Package building

The pipelines that build conda packages are used for both pull requests and push events in `main` and other branches. The only difference is that the packages built during a pull request are not uploaded to the staging channel. Maintaining these up-to-date across all feedstocks involves a number of repositories:

- `conda-smithy` is in charge of generating the CI pipelines themselves, together with the supporting scripts and configuration files. These pipelines and scripts can rely on code and data defined in the repositories below.
- `conda-forge-ci-setup-feedstock` provides the code needed to prepare and homogeneize the CI runners across providers.
- `conda-forge-pinning-feedstock` defines which versions are supported for a number of runtimes and libraries, as well as the compilers used for certain languages and platforms.
- `docker-images` builds the standardized container images for Linux runners.
  This repository has additional authentication needs for Docker Hub, Quay.io.

The pipelines can run on a number of CI providers supported by `conda-smithy`, including:

- Azure DevOps Pipelines
- Drone.io
- Travis CI
- Circle CI

Registration of hooks and triggers is also done by the `conda-smithy` app.

:::tip
`conda-smithy` supports more CI providers. Check [the repo][conda-smithy] for more details.
:::

Authenticated services involved:

- Anaconda.org uploads to `cf-staging`

## 4. Package validation and publication

Once built on `main` (or other branches), the conda packages are uploaded to an intermediary channel named `cf-staging`.
From there, the packages are downloaded by the validation server and, if successful, copied over to `conda-forge` itself.

- The validation logic is defined at `conda-forge/artifact-validation`
- If problematic, the results of the validation are posted as issues in the same repo.
- This logic runs at `conda-forge/conda-forge-webservices`.
  This webapp also copies the artifacts from `cf-staging` to `conda-forge`.
- Part of the validation includes checking for cross-package clobbering.
  The list of authorized feedstocks per package name is maintained at `conda-forge/feedstock-outputs`.
- Some further analysis might be performed _after_ publication.

Authenticated services involved:

- Anaconda.org uploads to `conda-forge`
- The `conda-forge-webservices` app deployment itself (currently at Heroku)
- (?) Post new issues to `conda-forge/artifact-validation`

## 5. Post-publication

Once uploaded to anaconda.org/conda-forge, packages are not immediately available to CLI clients.
They have to be replicated in the Content Distribution Network (CDN).
This step usually takes less than 15 minutes.

After CDN replication, most packages available on anaconda.org/conda-forge won't suffer any further modifications.
However, in some cases, maintainers might need to perform some actions on the published packages:

- A. Patching their repodata
- B. Marking them as broken

### 5A. Repodata patch

The metadata for `conda` packages is initially contained in each package archive (under `info/`).
`conda index` iterates over the published `conda` packages, extracts the metadata and consolidates all the found JSON blobs into a single JSON file: `repodata.json`.
This is the metadata file that the CLI clients download initially to _solve_ the environment.

Since the metadata is external to the files, some details can be modified without rebuilding packages,
which simplifies some maintenance tasks notably.

<!-- FIXME: Confirm accuracy of this paragraph -->

Repodata patches are created in `conda-forge/conda-forge-repodata-patches-feedstock`,
which generates (and uploads) a regular `conda` package as the result:
[`conda-forge-repodata-patches`](https://anaconda.org/conda-forge/conda-forge-repodata-patches/files).
Each of these timestamped packages contains the patch instructions for each channel subdir on conda-forge.
The Anaconda infrastructure takes the JSON files from these packages and applies them on top of the vanilla `repodata.json`.

Since this operates as a regular feedstock for the purposes of packages publication,
there are no further infrastructural details to cover.

### 5B. Mark a package as broken

Sometimes a package is faulty in ways that a repodata patch cannot amend (e.g. bad binary).
In these cases, conda-forge does not remove packages from Anaconda.org.
Instead, it marks them with `broken` label, which has a special meaning:
packages labeled as such will be removed from the repodata via automated patches.

The main repository handling this is `conda-forge/admin-requests`, which features different
Github Actions workflows running every 15 minutes.

For this task, the Github Action workflow needs access to:

- Anaconda.org, to add (or remove) labels
- Github, to modify and commit the input files after success

## Addendum: Operations on feedstocks {#operations-on-feedstocks}

Outside the package life cycle, there are some maintenance tasks that conda-forge has to perform every now and then.
All of these are automated, but some of them need to be manually requested and approved by `conda-forge/core`.

Some of these processes need to happen in an order dictated by the conda-forge dependencies graph,
while others can happen in any order.

Graph-depending changes:

- Propagation of a change in the conda-forge pinnings
- Support a new architecture

Non graph-depending changes:

- Source version updates
- Maintenance tasks (refresh credentials, infrastructure updates, ...)

:::info

"Rerendering" is the action of regenerating the supporting workflows, scripts and metadata that you find in every feedstock, next to the `recipe/` directory.
This action is done by `conda-smithy rerender`, which takes `recipe/meta.yaml`, `recipe/conda_build_config.yaml` and `conda-forge.yml` to produce the rest of the content you see in your feedstock.

That content is fed by two main sources:

- The templates defined in `conda-smithy` itself
- The conda-forge pinnings file defined in `conda-forge/conda-forge-pinnings-feedstock`

Anytime there's a change in either, all feedstocks are encouraged to rerender. However, most of the time the new configuration is only needed for the next build of the package. As a result, you can consider that rerenders are lazily delayed until they are needed. It's more efficient and CI-resources-friendly!

However, there are some exceptions, as discussed in this section.
:::

### Graph depending migrations

These changes cannot be applied to all the feedstocks in conda-forge in any random order because their success depends on the availability of packages produced by feedstocks that have already been updated. In other words, the changes need to be done in the order dictated by the conda-forge graph.

The conda-forge graph lists each feedstock _output_ as a node, and nodes connected by the outputs dependencies on each other (e.g. to migrate packages A, B and C, with A depending on B to run and/or be built, the bot would first migrate packages B and C, and A would only get the migration once B has been fully migrated). This is done through automated PRs that contain the migration file and the result of rerendering the feedstock. It's up to the feedstock maintainers to review and merge those PRs, since sometimes the PR introduces changes that do not pass the CI immediately (e.g. updating the pinned version of `openssl` to its newest release, which introduced API incompatible changes that break our package tests). Once merged, that feedstock has successfully completed its part of the migration and the bot can issue the PRs for the dependent feedstocks.

Once the graph is (mostly) migrated, the migration process is "closed", which means that the global file now contains the results of the migration file.

Where are all these pieces of infrastructure defined?

The bot network is built with:

- `regro/cf-scripts`: the logic encoding how to apply the changes driven by the migration scheme
- `regro/autotick-bot`: the CI workflows running the migration logic

The graph metadata is fed by:

- `regro/libcfgraph`, as computed by `regro/libcflib`
- `regro/cf-graph-countyfair`
-

## The progress reports are displayed in:

-
-

The most popular graph-dependent migrations are:

- A change in the conda-forge pinnings
- New architectures added

#### Pinnings migrations

<!-- TODO: Put this in the maintainer's guide and link to it in the list above -->

The conda-forge pinnings file is the single source of truth for ABI stability for all conda-forge. Every feedstock contains the subset of that pinnings file that the recipe requires (thanks to `conda-smithy rerender`, which drops platform-specific configurations in the `.ci_support/` directory). With thousands of feedstocks, it wouldn't make sense to rerender all of them just because one definition in that pinnings file has changed. A definition that might not have any impact in that feedstock.

This is why conda-forge uses a special bot to issue those rerender requests through the subset of the feedstock graph that need that "upgrade". The change is not applied to the global file from the beginning; instead, a _migration file_ is created, which contains the operations that would transform the global file into a fully migrated one. When `conda-smithy rerender` finds a migration file under `.ci_support/migrations`, it applies those operations to the global pinnings file, thus migrating that feedstock! Note that several migration files can coexist in the same feedstock at a given time.

<!-- WIP -->

#### Architecture migrations

<!-- TODO: Put this in the maintainer's guide and link to it in the list above -->

WIP.

### Source version updates

WIP.

### Automated maintenance

Most of these tasks are taken care by `conda-forge/admin-migrations`.

<!-- TODO: Elaborate -->

#### Maintenance rerenders

Each feedstock is equipped with a Github Actions worfklow file defined by the `conda-smithy` templates. The `.github/workflows/webservices.yml` workflow is configured to be triggered on `repository_dispatch` events. It contains an instance of the `conda-forge/webservices-dispatch-action` Github Actions action, which defines several tasks, including:

- Rerendering the feedstock without human intervention

When needed, the conda-forge webservices bot can issue a rerender by triggering that workflow via the required payload. This can be requested by core members in... <!-- FIXME: How? -->

### Manual maintenance

These happen via `conda-forge/admin-requests`.

#### Archive a feedstock

Feedstocks may no longer be required for a number of reasons (mostly, being superseded by another one). In these cases, maintainers can request the feedstock be archived. This is also requested via PRs to `conda-forge/admin-requests` and handled by its Github Actions workflows.

This time, only Github access is needed.

#### Regenerate tokens

Each feedstock has access to a series of external services, most of them requiring authentication.
Tokens are granted during the feedstock creation process, via `conda-smithy`.
However, sometimes this process can fail or tokens might expire.

In `conda-forge/admin-requests`, maintainers can request that the tokens of a feedstock are regenerated.

This task is also done via the same workflow, but in this case it requires several authentication tokens so `conda-smithy` can issue the required requests. Namely:

- Uploads to Anaconda.org/cf-staging
- CI Services: Azure, Travis, Circle, Drone
- Github: Write access is also needed so the worfklow can commit the changes to the repository

<!-- LINKS -->

[conda-smithy]: https://github.com/conda-forge/conda-smithy
